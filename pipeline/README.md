# ğŸš° ETL Pipeline

This directory contains the scripts used to extract, transform, and load BandCamp API data into an RDS database.
We will also use a web scraper to gain additional data such as tag data and release dates.

## ğŸ“ File Structure

### ğŸ“ƒ ETL Scripts

- `extract.py` â€“ Extracts Bandcamp sales data and saves to CSV  
- `web_scraper.py` - Extracts data by scraping the api.
- `transform.py` â€“ Cleans and transforms data for loading  
- `load.py` â€“ Loads transformed data into an RDS database 
- `etl_controller.py` - Runs all stages of the ETL pipeline (contains Lambda Handler).

### ğŸ§ª Tests
- `test_exist.py` â€“ Test that checks existence of `extract.py`. Ensures pytest succeeds if there are no other tests. 
- `test_extract.py` â€“ Tests for `extract.py`  
- `test_transform.py` â€“ Tests for `transform.py`  
- `test_load.py` â€“ Tests for `load.py` 
- `test_etl_controller.py` - Tests for `etl_controller.py`
- `test_web_scraper.py` - Tests for `web_scraper.py`

### ğŸ› ï¸ Utilities & Other Scripts
- `utilities.py` â€“ Helper functions used across ETL scripts  
- `requirements.txt` â€“ Python dependencies  
- `Dockerfile` - File for dockerising the ETL pipeline.
- `conftest.py` - Contains all of the fixtures used in the tests.
- `schema.sql` - Script containing all of the queries required to create the database.


### ğŸƒğŸ’¨ Instructions
When you have the .env information, simply run the following in the command line.
```
python3 etl_controller.py
```

